{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U numpy\n",
    "%pip install -U matplotlib\n",
    "\n",
    "# Importante para o correto funcionamento do MPS no Apple Silicon (GPU)\n",
    "%pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cpu\n",
    "# ou\n",
    "# Caso vc não use MPS/Apple Silicon (CPU ou Cuda)\n",
    "# %pip install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "# Checa se tem device NVIDIA ou MPS (mac gpu)\n",
    "if(torch.cuda.is_available()):\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# simplificar a visualização dos tensores\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "#torch.set_default_device(device)\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(device.type == 'mps'):\n",
    "    import os\n",
    "    # .env\n",
    "    # PYTORCH_ENABLE_MPS_FALLBACK=1\n",
    "\n",
    "    # ou\n",
    "    # os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "\n",
    "    # PYTORCH_ENABLE_MPS_FALLBACK=1 (importante para o funcionamento em Apple Silicon MPS)\n",
    "    # Support a operacoes de complex numbers não são suportadas ainda por Apple Silicon MPS\n",
    "    print(f\"PYTORCH_ENABLE_MPS_FALLBACK={os.environ['PYTORCH_ENABLE_MPS_FALLBACK']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (tok_embeddings): Embedding(4, 8)\n",
       "  (layers): ModuleList(\n",
       "    (0): TransformerBlock(\n",
       "      (attention): Attention(\n",
       "        (wq): Linear(in_features=8, out_features=8, bias=False)\n",
       "        (wk): Linear(in_features=8, out_features=16, bias=False)\n",
       "        (wv): Linear(in_features=8, out_features=16, bias=False)\n",
       "        (wo): Linear(in_features=8, out_features=8, bias=False)\n",
       "      )\n",
       "      (feed_forward): FeedForward(\n",
       "        (w1): Linear(in_features=8, out_features=22, bias=False)\n",
       "        (w2): Linear(in_features=22, out_features=8, bias=False)\n",
       "        (w3): Linear(in_features=8, out_features=22, bias=False)\n",
       "      )\n",
       "      (attention_norm): RMSNorm()\n",
       "      (ffn_norm): RMSNorm()\n",
       "    )\n",
       "  )\n",
       "  (norm): RMSNorm()\n",
       "  (output): Linear(in_features=8, out_features=4, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "@dataclass\n",
    "class ModelArgs:\n",
    "    dim: int = 8\n",
    "    n_layers: int = 1\n",
    "    n_heads: int = 1\n",
    "    #n_kv_heads: Optional[int] = None\n",
    "    n_kv_heads: int = 2 # deve ser menor ou igual a n_heads\n",
    "    vocab_size: int = 4  # defined later by tokenizer\n",
    "    multiple_of: int = 2  # make SwiGLU hidden layer size multiple of large power of 2\n",
    "    ffn_dim_multiplier: Optional[float] = None\n",
    "    norm_eps: float = 1e-5\n",
    "\n",
    "    max_batch_size: int = 1\n",
    "    max_seq_len: int = 5\n",
    "\n",
    "\n",
    "class RMSNorm(torch.nn.Module):\n",
    "    def __init__(self, dim: int, eps: float = 1e-6):\n",
    "        \"\"\"\n",
    "        Initialize the RMSNorm normalization layer.\n",
    "\n",
    "        Args:\n",
    "            dim (int): The dimension of the input tensor.\n",
    "            eps (float, optional): A small value added to the denominator for numerical stability. Default is 1e-6.\n",
    "\n",
    "        Attributes:\n",
    "            eps (float): A small value added to the denominator for numerical stability.\n",
    "            weight (nn.Parameter): Learnable scaling parameter.\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "\n",
    "    def _norm(self, x):\n",
    "        \"\"\"\n",
    "        Apply the RMSNorm normalization to the input tensor.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): The input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The normalized tensor.\n",
    "\n",
    "        \"\"\"\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the RMSNorm layer.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): The input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The output tensor after applying RMSNorm.\n",
    "\n",
    "        \"\"\"\n",
    "        output = self._norm(x.float()).type_as(x)\n",
    "        return output * self.weight\n",
    "\n",
    "\n",
    "def precompute_freqs_cis(dim: int, end: int, theta: float = 10000.0):\n",
    "    \"\"\"\n",
    "    Precompute the frequency tensor for complex exponentials (cis) with given dimensions.\n",
    "\n",
    "    This function calculates a frequency tensor with complex exponentials using the given dimension 'dim'\n",
    "    and the end index 'end'. The 'theta' parameter scales the frequencies.\n",
    "    The returned tensor contains complex values in complex64 data type.\n",
    "\n",
    "    Args:\n",
    "        dim (int): Dimension of the frequency tensor.\n",
    "        end (int): End index for precomputing frequencies.\n",
    "        theta (float, optional): Scaling factor for frequency computation. Defaults to 10000.0.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Precomputed frequency tensor with complex exponentials.\n",
    "\n",
    "    \n",
    "        \n",
    "\n",
    "    \"\"\"\n",
    "    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
    "    t = torch.arange(end, device=freqs.device)  # type: ignore\n",
    "    freqs = torch.outer(t, freqs).float()  # type: ignore\n",
    "    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n",
    "    return freqs_cis\n",
    "\n",
    "\n",
    "def reshape_for_broadcast(freqs_cis: torch.Tensor, x: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Reshape frequency tensor for broadcasting it with another tensor.\n",
    "\n",
    "    This function reshapes the frequency tensor to have the same shape as the target tensor 'x'\n",
    "    for the purpose of broadcasting the frequency tensor during element-wise operations.\n",
    "\n",
    "    Args:\n",
    "        freqs_cis (torch.Tensor): Frequency tensor to be reshaped.\n",
    "        x (torch.Tensor): Target tensor for broadcasting compatibility.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Reshaped frequency tensor.\n",
    "\n",
    "    Raises:\n",
    "        AssertionError: If the frequency tensor doesn't match the expected shape.\n",
    "        AssertionError: If the target tensor 'x' doesn't have the expected number of dimensions.\n",
    "    \"\"\"\n",
    "    ndim = x.ndim\n",
    "    assert 0 <= 1 < ndim\n",
    "    assert freqs_cis.shape == (x.shape[1], x.shape[-1])\n",
    "    shape = [d if i == 1 or i == ndim - 1 else 1 for i, d in enumerate(x.shape)]\n",
    "    return freqs_cis.view(*shape)\n",
    "\n",
    "\n",
    "def apply_rotary_emb(\n",
    "    xq: torch.Tensor,\n",
    "    xk: torch.Tensor,\n",
    "    freqs_cis: torch.Tensor,\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Apply rotary embeddings to input tensors using the given frequency tensor.\n",
    "\n",
    "    This function applies rotary embeddings to the given query 'xq' and key 'xk' tensors using the provided\n",
    "    frequency tensor 'freqs_cis'. The input tensors are reshaped as complex numbers, and the frequency tensor\n",
    "    is reshaped for broadcasting compatibility. The resulting tensors contain rotary embeddings and are\n",
    "    returned as real tensors.\n",
    "\n",
    "    Args:\n",
    "        xq (torch.Tensor): Query tensor to apply rotary embeddings.\n",
    "        xk (torch.Tensor): Key tensor to apply rotary embeddings.\n",
    "        freqs_cis (torch.Tensor): Precomputed frequency tensor for complex exponentials.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[torch.Tensor, torch.Tensor]: Tuple of modified query tensor and key tensor with rotary embeddings.\n",
    "\n",
    "        \n",
    "\n",
    "    \"\"\"\n",
    "    xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2))\n",
    "    xk_ = torch.view_as_complex(xk.float().reshape(*xk.shape[:-1], -1, 2))\n",
    "    freqs_cis = reshape_for_broadcast(freqs_cis, xq_)\n",
    "    xq_out = torch.view_as_real(xq_ * freqs_cis).flatten(3)\n",
    "    xk_out = torch.view_as_real(xk_ * freqs_cis).flatten(3)\n",
    "    return xq_out.type_as(xq), xk_out.type_as(xk)\n",
    "\n",
    "\n",
    "def repeat_kv(x: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
    "    \"\"\"torch.repeat_interleave(x, dim=2, repeats=n_rep)\"\"\"\n",
    "    bs, slen, n_kv_heads, head_dim = x.shape\n",
    "    if n_rep == 1:\n",
    "        return x\n",
    "    return (\n",
    "        x[:, :, :, None, :]\n",
    "        .expand(bs, slen, n_kv_heads, n_rep, head_dim)\n",
    "        .reshape(bs, slen, n_kv_heads * n_rep, head_dim)\n",
    "    )\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    \"\"\"Multi-head attention module.\"\"\"\n",
    "    def __init__(self, args: ModelArgs):\n",
    "        \"\"\"\n",
    "        Initialize the Attention module.\n",
    "\n",
    "        Args:\n",
    "            args (ModelArgs): Model configuration parameters.\n",
    "\n",
    "        Attributes:\n",
    "            n_kv_heads (int): Number of key and value heads.\n",
    "            n_local_heads (int): Number of local query heads.\n",
    "            n_local_kv_heads (int): Number of local key and value heads.\n",
    "            n_rep (int): Number of repetitions for local heads.\n",
    "            head_dim (int): Dimension size of each attention head.\n",
    "            wq (ColumnParallelLinear): Linear transformation for queries.\n",
    "            wk (ColumnParallelLinear): Linear transformation for keys.\n",
    "            wv (ColumnParallelLinear): Linear transformation for values.\n",
    "            wo (RowParallelLinear): Linear transformation for output.\n",
    "            cache_k (torch.Tensor): Cached keys for attention.\n",
    "            cache_v (torch.Tensor): Cached values for attention.\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.n_kv_heads = args.n_heads if args.n_kv_heads is None else args.n_kv_heads\n",
    "        self.n_local_heads = args.n_heads\n",
    "        self.n_local_kv_heads = self.n_kv_heads\n",
    "        self.n_rep = self.n_local_heads // self.n_local_kv_heads\n",
    "        self.head_dim = args.dim // args.n_heads\n",
    "\n",
    "        self.wq = nn.Linear(\n",
    "            args.dim,\n",
    "            args.n_heads * self.head_dim,\n",
    "            bias=False\n",
    "        )\n",
    "        self.wk = nn.Linear(\n",
    "            args.dim,\n",
    "            self.n_kv_heads * self.head_dim,\n",
    "            bias=False\n",
    "        )\n",
    "        self.wv = nn.Linear(\n",
    "            args.dim,\n",
    "            self.n_kv_heads * self.head_dim,\n",
    "            bias=False\n",
    "        )\n",
    "        self.wo = nn.Linear(\n",
    "            args.n_heads * self.head_dim,\n",
    "            args.dim,\n",
    "            bias=False\n",
    "        )\n",
    "\n",
    "        self.cache_k = torch.zeros(\n",
    "            (\n",
    "                args.max_batch_size,\n",
    "                args.max_seq_len,\n",
    "                self.n_local_kv_heads,\n",
    "                self.head_dim,\n",
    "            )\n",
    "        ).to(device)\n",
    "        self.cache_v = torch.zeros(\n",
    "            (\n",
    "                args.max_batch_size,\n",
    "                args.max_seq_len,\n",
    "                self.n_local_kv_heads,\n",
    "                self.head_dim,\n",
    "            )\n",
    "        ).to(device)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        start_pos: int,\n",
    "        freqs_cis: torch.Tensor,\n",
    "        mask: Optional[torch.Tensor],\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Forward pass of the attention module.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor.\n",
    "            start_pos (int): Starting position for caching.\n",
    "            freqs_cis (torch.Tensor): Precomputed frequency tensor.\n",
    "            mask (torch.Tensor, optional): Attention mask tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor after attention.\n",
    "\n",
    "        \"\"\"\n",
    "        bsz, seqlen, _ = x.shape\n",
    "        xq, xk, xv = self.wq(x), self.wk(x), self.wv(x)\n",
    "\n",
    "        xq = xq.view(bsz, seqlen, self.n_local_heads, self.head_dim)\n",
    "        xk = xk.view(bsz, seqlen, self.n_local_kv_heads, self.head_dim)\n",
    "        xv = xv.view(bsz, seqlen, self.n_local_kv_heads, self.head_dim)\n",
    "\n",
    "        xq, xk = apply_rotary_emb(xq, xk, freqs_cis=freqs_cis)\n",
    "\n",
    "        self.cache_k = self.cache_k.to(xq)\n",
    "        self.cache_v = self.cache_v.to(xq)\n",
    "\n",
    "        self.cache_k[:bsz, start_pos : start_pos + seqlen] = xk\n",
    "        self.cache_v[:bsz, start_pos : start_pos + seqlen] = xv\n",
    "\n",
    "        keys = self.cache_k[:bsz, : start_pos + seqlen]\n",
    "        values = self.cache_v[:bsz, : start_pos + seqlen]\n",
    "\n",
    "        # repeat k/v heads if n_kv_heads < n_heads\n",
    "        keys = repeat_kv(keys, self.n_rep)  # (bs, cache_len + seqlen, n_local_heads, head_dim)\n",
    "        values = repeat_kv(values, self.n_rep)  # (bs, cache_len + seqlen, n_local_heads, head_dim)\n",
    "\n",
    "        xq = xq.transpose(1, 2)  # (bs, n_local_heads, seqlen, head_dim)\n",
    "        keys = keys.transpose(1, 2) # (bs, n_local_heads, cache_len + seqlen, head_dim)\n",
    "        values = values.transpose(1, 2) # (bs, n_local_heads, cache_len + seqlen, head_dim)\n",
    "        scores = torch.matmul(xq, keys.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
    "        if mask is not None:\n",
    "            scores = scores + mask  # (bs, n_local_heads, seqlen, cache_len + seqlen)\n",
    "        scores = F.softmax(scores.float(), dim=-1).type_as(xq)\n",
    "        output = torch.matmul(scores, values)  # (bs, n_local_heads, seqlen, head_dim)\n",
    "        output = output.transpose(1, 2).contiguous().view(bsz, seqlen, -1)\n",
    "        return self.wo(output)\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int,\n",
    "        hidden_dim: int,\n",
    "        multiple_of: int,\n",
    "        ffn_dim_multiplier: Optional[float],\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the FeedForward module.\n",
    "\n",
    "        Args:\n",
    "            dim (int): Input dimension.\n",
    "            hidden_dim (int): Hidden dimension of the feedforward layer.\n",
    "            multiple_of (int): Value to ensure hidden dimension is a multiple of this value.\n",
    "            ffn_dim_multiplier (float, optional): Custom multiplier for hidden dimension. Defaults to None.\n",
    "\n",
    "        Attributes:\n",
    "            w1 (ColumnParallelLinear): Linear transformation for the first layer.\n",
    "            w2 (RowParallelLinear): Linear transformation for the second layer.\n",
    "            w3 (ColumnParallelLinear): Linear transformation for the third layer.\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        hidden_dim = int(2 * hidden_dim / 3)\n",
    "        # custom dim factor multiplier\n",
    "        if ffn_dim_multiplier is not None:\n",
    "            hidden_dim = int(ffn_dim_multiplier * hidden_dim)\n",
    "        hidden_dim = multiple_of * ((hidden_dim + multiple_of - 1) // multiple_of)\n",
    "\n",
    "        self.w1 = nn.Linear(\n",
    "            dim, hidden_dim, bias=False\n",
    "        )\n",
    "        self.w2 = nn.Linear(\n",
    "            hidden_dim, dim, bias=False\n",
    "        )\n",
    "        self.w3 = nn.Linear(\n",
    "            dim, hidden_dim, bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w2(F.silu(self.w1(x)) * self.w3(x))\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, layer_id: int, args: ModelArgs):\n",
    "        \"\"\"\n",
    "        Initialize a TransformerBlock.\n",
    "\n",
    "        Args:\n",
    "            layer_id (int): Identifier for the layer.\n",
    "            args (ModelArgs): Model configuration parameters.\n",
    "\n",
    "        Attributes:\n",
    "            n_heads (int): Number of attention heads.\n",
    "            dim (int): Dimension size of the model.\n",
    "            head_dim (int): Dimension size of each attention head.\n",
    "            attention (Attention): Attention module.\n",
    "            feed_forward (FeedForward): FeedForward module.\n",
    "            layer_id (int): Identifier for the layer.\n",
    "            attention_norm (RMSNorm): Layer normalization for attention output.\n",
    "            ffn_norm (RMSNorm): Layer normalization for feedforward output.\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.n_heads = args.n_heads\n",
    "        self.dim = args.dim\n",
    "        self.head_dim = args.dim // args.n_heads\n",
    "        self.attention = Attention(args)\n",
    "        self.feed_forward = FeedForward(\n",
    "            dim=args.dim,\n",
    "            hidden_dim=4 * args.dim,\n",
    "            multiple_of=args.multiple_of,\n",
    "            ffn_dim_multiplier=args.ffn_dim_multiplier,\n",
    "        )\n",
    "        self.layer_id = layer_id\n",
    "        self.attention_norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
    "        self.ffn_norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        start_pos: int,\n",
    "        freqs_cis: torch.Tensor,\n",
    "        mask: Optional[torch.Tensor],\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Perform a forward pass through the TransformerBlock.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor.\n",
    "            start_pos (int): Starting position for attention caching.\n",
    "            freqs_cis (torch.Tensor): Precomputed cosine and sine frequencies.\n",
    "            mask (torch.Tensor, optional): Masking tensor for attention. Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor after applying attention and feedforward layers.\n",
    "\n",
    "        \"\"\"\n",
    "        h = x + self.attention.forward(\n",
    "            self.attention_norm(x), start_pos, freqs_cis, mask\n",
    "        )\n",
    "        out = h + self.feed_forward.forward(self.ffn_norm(h))\n",
    "        return out\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, params: ModelArgs):\n",
    "        \"\"\"\n",
    "        Initialize a Transformer model.\n",
    "\n",
    "        Args:\n",
    "            params (ModelArgs): Model configuration parameters.\n",
    "\n",
    "        Attributes:\n",
    "            params (ModelArgs): Model configuration parameters.\n",
    "            vocab_size (int): Vocabulary size.\n",
    "            n_layers (int): Number of layers in the model.\n",
    "            tok_embeddings (ParallelEmbedding): Token embeddings.\n",
    "            layers (torch.nn.ModuleList): List of Transformer blocks.\n",
    "            norm (RMSNorm): Layer normalization for the model output.\n",
    "            output (ColumnParallelLinear): Linear layer for final output.\n",
    "            freqs_cis (torch.Tensor): Precomputed cosine and sine frequencies.\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.params = params\n",
    "        self.vocab_size = params.vocab_size\n",
    "        self.n_layers = params.n_layers\n",
    "\n",
    "        self.tok_embeddings = nn.Embedding(\n",
    "            params.vocab_size, params.dim\n",
    "        )\n",
    "\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for layer_id in range(params.n_layers):\n",
    "            self.layers.append(TransformerBlock(layer_id, params))\n",
    "\n",
    "        self.norm = RMSNorm(params.dim, eps=params.norm_eps)\n",
    "        self.output = nn.Linear(\n",
    "            params.dim, params.vocab_size, bias=False\n",
    "        )\n",
    "\n",
    "        self.freqs_cis = precompute_freqs_cis(\n",
    "            # Note that self.params.max_seq_len is multiplied by 2 because the token limit for the Llama 2 generation of models is 4096. \n",
    "            # Adding this multiplier instead of using 4096 directly allows for dynamism of token lengths while training or fine-tuning.\n",
    "            self.params.dim // self.params.n_heads, self.params.max_seq_len * 2\n",
    "        )\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def forward(self, tokens: torch.Tensor, start_pos: int):\n",
    "        \"\"\"\n",
    "        Perform a forward pass through the Transformer model.\n",
    "\n",
    "        Args:\n",
    "            tokens (torch.Tensor): Input token indices.\n",
    "            start_pos (int): Starting position for attention caching.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output logits after applying the Transformer model.\n",
    "\n",
    "        \"\"\"\n",
    "        _bsz, seqlen = tokens.shape\n",
    "        h = self.tok_embeddings(tokens)\n",
    "        self.freqs_cis = self.freqs_cis.to(h.device)\n",
    "        freqs_cis = self.freqs_cis[start_pos : start_pos + seqlen]\n",
    "\n",
    "        mask = None\n",
    "        if seqlen > 1:\n",
    "            mask = torch.full((seqlen, seqlen), float(\"-inf\")) # use cpu here to fix MPS nan values to torch.triu\n",
    "\n",
    "            mask = torch.triu(mask, diagonal=1)\n",
    "\n",
    "            # When performing key-value caching, we compute the attention scores\n",
    "            # only for the new sequence. Thus, the matrix of scores is of size\n",
    "            # (seqlen, cache_len + seqlen), and the only masked entries are (i, j) for\n",
    "            # j > cache_len + i, since row i corresponds to token cache_len + i.\n",
    "            mask = torch.hstack([\n",
    "                torch.zeros((seqlen, start_pos)), mask\n",
    "            ]).type_as(h) # here will move from cpu to device\n",
    "\n",
    "            #mask = mask.to(device) # .type_as(h) # already moved from cpu to device\n",
    "\n",
    "        for layer in self.layers:\n",
    "            h = layer(h, start_pos, freqs_cis, mask)\n",
    "        h = self.norm(h)\n",
    "        output = self.output(h).float()\n",
    "        return output\n",
    "\n",
    "model_args = ModelArgs()\n",
    "model = Transformer(model_args)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estrategia de Seleção de Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_top_p(probs, p):\n",
    "    \"\"\"\n",
    "    Perform top-p (nucleus) sampling on a probability distribution.\n",
    "\n",
    "    Args:\n",
    "        probs (torch.Tensor): Probability distribution tensor.\n",
    "        p (float): Probability threshold for top-p sampling.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Sampled token indices.\n",
    "\n",
    "    Note:\n",
    "        Top-p sampling selects the smallest set of tokens whose cumulative probability mass\n",
    "        exceeds the threshold p. The distribution is renormalized based on the selected tokens.\n",
    "\n",
    "    \"\"\"\n",
    "    probs_sort, probs_idx = torch.sort(probs, dim=-1, descending=True)\n",
    "    probs_sum = torch.cumsum(probs_sort, dim=-1)\n",
    "    mask = probs_sum - probs_sort > p\n",
    "    probs_sort[mask] = 0.0\n",
    "    probs_sort.div_(probs_sort.sum(dim=-1, keepdim=True))\n",
    "    next_token = torch.multinomial(probs_sort, num_samples=1)\n",
    "    next_token = torch.gather(probs_idx, -1, next_token)\n",
    "    return next_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Função de Geração de Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Literal, Optional, Tuple, TypedDict\n",
    "\n",
    "pad_id = 0\n",
    "eos_id = 1\n",
    "max_seq_len = 100\n",
    "\n",
    "@torch.inference_mode()\n",
    "def generate(\n",
    "    prompt_tokens: List[List[int]],\n",
    "    max_gen_len: int,\n",
    "    temperature: float = 0.6,\n",
    "    top_p: float = 0.9,\n",
    "    logprobs: bool = False,\n",
    "    echo: bool = False,\n",
    ") -> Tuple[List[List[int]], Optional[List[List[float]]]]:\n",
    "    \"\"\"\n",
    "    Generate text sequences based on provided prompts using the language generation model.\n",
    "\n",
    "    Args:\n",
    "        prompt_tokens (List[List[int]]): List of tokenized prompts, where each prompt is represented as a list of integers.\n",
    "        max_gen_len (int): Maximum length of the generated text sequence.\n",
    "        temperature (float, optional): Temperature value for controlling randomness in sampling. Defaults to 0.6.\n",
    "        top_p (float, optional): Top-p probability threshold for nucleus sampling. Defaults to 0.9.\n",
    "        logprobs (bool, optional): Flag indicating whether to compute token log probabilities. Defaults to False.\n",
    "        echo (bool, optional): Flag indicating whether to include prompt tokens in the generated output. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[List[int]], Optional[List[List[float]]]]: A tuple containing generated token sequences and, if logprobs is True, corresponding token log probabilities.\n",
    "\n",
    "    Note:\n",
    "        This method uses the provided prompts as a basis for generating text. It employs nucleus sampling to produce text with controlled randomness.\n",
    "        If logprobs is True, token log probabilities are computed for each generated token.\n",
    "\n",
    "    \"\"\"\n",
    "    bsz = len(prompt_tokens)\n",
    "\n",
    "    min_prompt_len = min(len(t) for t in prompt_tokens)\n",
    "    max_prompt_len = max(len(t) for t in prompt_tokens)\n",
    "\n",
    "    total_len = min(max_seq_len, max_gen_len + max_prompt_len)\n",
    "\n",
    "    tokens = torch.full((bsz, total_len), pad_id, dtype=torch.long, device=device)\n",
    "    for k, t in enumerate(prompt_tokens):\n",
    "        #tokens[k, : len(t)] = torch.tensor(t, dtype=torch.long, device=device\")\n",
    "        tokens[k, : len(t)] = t.clone().detach().to(dtype=torch.long, device=device)\n",
    "    if logprobs:\n",
    "        token_logprobs = torch.zeros_like(tokens, dtype=torch.float)\n",
    "\n",
    "    prev_pos = 0\n",
    "    eos_reached = torch.tensor([False] * bsz, device=device)\n",
    "    input_text_mask = tokens != pad_id\n",
    "    if min_prompt_len == total_len:\n",
    "        logits = model.forward(tokens, prev_pos)\n",
    "        token_logprobs = -F.cross_entropy(\n",
    "            input=logits.transpose(1, 2),\n",
    "            target=tokens,\n",
    "            reduction=\"none\",\n",
    "            ignore_index=pad_id,\n",
    "            #ignore_index=1000,\n",
    "        )\n",
    "\n",
    "    for cur_pos in range(min_prompt_len, total_len):\n",
    "        logits = model.forward(tokens[:, prev_pos:cur_pos], prev_pos)\n",
    "        if temperature > 0:\n",
    "            probs = torch.softmax(logits[:, -1] / temperature, dim=-1)\n",
    "            next_token = sample_top_p(probs, top_p)\n",
    "        else:\n",
    "            next_token = torch.argmax(logits[:, -1], dim=-1)\n",
    "\n",
    "        next_token = next_token.reshape(-1)\n",
    "        # only replace token if prompt has already been generated\n",
    "        next_token = torch.where(\n",
    "            input_text_mask[:, cur_pos], tokens[:, cur_pos], next_token\n",
    "        )\n",
    "        tokens[:, cur_pos] = next_token\n",
    "        if logprobs:\n",
    "            token_logprobs[:, prev_pos + 1 : cur_pos + 1] = -F.cross_entropy(\n",
    "                input=logits.transpose(1, 2),\n",
    "                target=tokens[:, prev_pos + 1 : cur_pos + 1],\n",
    "                reduction=\"none\",\n",
    "                #ignore_index=pad_id,\n",
    "            )\n",
    "        eos_reached |= (~input_text_mask[:, cur_pos]) & (next_token == eos_id)\n",
    "        prev_pos = cur_pos\n",
    "        if all(eos_reached):\n",
    "            break\n",
    "\n",
    "    if logprobs:\n",
    "        token_logprobs = token_logprobs.tolist()\n",
    "    out_tokens, out_logprobs = [], []\n",
    "    for i, toks in enumerate(tokens.tolist()):\n",
    "        # cut to max gen len\n",
    "        start = 0 if echo else len(prompt_tokens[i])\n",
    "        toks = toks[start : len(prompt_tokens[i]) + max_gen_len]\n",
    "        probs = None\n",
    "        if logprobs:\n",
    "            probs = token_logprobs[i][start : len(prompt_tokens[i]) + max_gen_len]\n",
    "        # cut to eos tok if any\n",
    "        if eos_id in toks:\n",
    "            eos_idx = toks.index(eos_id)\n",
    "            toks = toks[:eos_idx]\n",
    "            probs = probs[:eos_idx] if logprobs else None\n",
    "        out_tokens.append(toks)\n",
    "        out_logprobs.append(probs)\n",
    "    return (out_tokens, out_logprobs if logprobs else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemplo de geracao de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (2x0 and 8x8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m prompt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m----> 2\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt_tokens\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_gen_len\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# result: Tuple[List[List[int]], Optional[List[List[float]]]]:\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 63\u001b[0m, in \u001b[0;36mgenerate\u001b[0;34m(prompt_tokens, max_gen_len, temperature, top_p, logprobs, echo)\u001b[0m\n\u001b[1;32m     54\u001b[0m     token_logprobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mF\u001b[38;5;241m.\u001b[39mcross_entropy(\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mlogits\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m     56\u001b[0m         target\u001b[38;5;241m=\u001b[39mtokens,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;66;03m#ignore_index=1000,\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     )\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cur_pos \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(min_prompt_len, total_len):\n\u001b[0;32m---> 63\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev_pos\u001b[49m\u001b[43m:\u001b[49m\u001b[43mcur_pos\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev_pos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m temperature \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     65\u001b[0m         probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(logits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m temperature, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 469\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, tokens, start_pos)\u001b[0m\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;66;03m#mask = mask.to(device) # .type_as(h) # already moved from cpu to device\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 469\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreqs_cis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    470\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(h)\n\u001b[1;32m    471\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(h)\u001b[38;5;241m.\u001b[39mfloat()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 384\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, x, start_pos, freqs_cis, mask)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    366\u001b[0m     x: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    369\u001b[0m     mask: Optional[torch\u001b[38;5;241m.\u001b[39mTensor],\n\u001b[1;32m    370\u001b[0m ):\n\u001b[1;32m    371\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03m    Perform a forward pass through the TransformerBlock.\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m \n\u001b[1;32m    383\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 384\u001b[0m     h \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreqs_cis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m     out \u001b[38;5;241m=\u001b[39m h \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeed_forward\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mffn_norm(h))\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "Cell \u001b[0;32mIn[4], line 282\u001b[0m, in \u001b[0;36mAttention.forward\u001b[0;34m(self, x, start_pos, freqs_cis, mask)\u001b[0m\n\u001b[1;32m    280\u001b[0m output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(scores, values)  \u001b[38;5;66;03m# (bs, n_local_heads, seqlen, head_dim)\u001b[39;00m\n\u001b[1;32m    281\u001b[0m output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(bsz, seqlen, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwo\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2x0 and 8x8)"
     ]
    }
   ],
   "source": [
    "prompt = torch.tensor([[2,3]], dtype=torch.long, device=device)\n",
    "result = generate(\n",
    "    prompt_tokens = prompt,\n",
    "    max_gen_len = 3,\n",
    "    logprobs = True\n",
    ")\n",
    "# result: Tuple[List[List[int]], Optional[List[List[float]]]]:\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RoPE (Rotary Posicional Embedding)\n",
    "\n",
    "paper: https://arxiv.org/pdf/2104.09864v5.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 12])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def precompute_freqs_cis2(dim: int, end: int, theta: float = 10000.0):\n",
    "    \"\"\"\n",
    "    Precompute the frequency tensor for complex exponentials (cis) with given dimensions.\n",
    "\n",
    "    This function calculates a frequency tensor with complex exponentials using the given dimension 'dim'\n",
    "    and the end index 'end'. The 'theta' parameter scales the frequencies.\n",
    "    The returned tensor contains complex values in complex64 data type.\n",
    "\n",
    "    Args:\n",
    "        dim (int): Dimension of the frequency tensor.\n",
    "        end (int): End index for precomputing frequencies.\n",
    "        theta (float, optional): Scaling factor for frequency computation. Defaults to 10000.0.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Precomputed frequency tensor with complex exponentials.\n",
    "\n",
    "    \n",
    "        \n",
    "\n",
    "    \"\"\"\n",
    "    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
    "    t = torch.arange(end, device=freqs.device)  # type: ignore\n",
    "    freqs = torch.outer(t, freqs).float()  # type: ignore\n",
    "    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n",
    "    return freqs_cis\n",
    "\n",
    "my_freqs = precompute_freqs_cis2(24, 10)\n",
    "my_freqs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RoPE Visualization (Rotary Posicional Embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 12])\n",
      "(10, 12)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "y , x = my_freqs.shape\n",
    "\n",
    "# Matriz a ser rotacionada (conversao para numpy)\n",
    "rotation_matrix = my_freqs.numpy()\n",
    "\n",
    "# Calculo do angulo de rotacao com base nos numeros complexos\n",
    "angles = np.angle(rotation_matrix)\n",
    "\n",
    "print(my_freqs.shape)\n",
    "print(angles.shape)\n",
    "\n",
    "# Angulos normalizados entre 0 e 1: color mapping\n",
    "normalized_angles = (angles - np.min(angles)) / (np.max(angles) - np.min(angles))\n",
    "\n",
    "# Criação do color map\n",
    "cmap = plt.cm.viridis\n",
    "\n",
    "# Array de indices para os eixos x e y\n",
    "col_indices = np.arange(x)\n",
    "row_indices = np.arange(y)\n",
    "\n",
    "# Plotting da matriz com variação de cores\n",
    "plt.figure(figsize=(x, y))\n",
    "plt.imshow(normalized_angles, cmap=cmap, aspect='auto')\n",
    "\n",
    "# Setando os ticks\n",
    "plt.xticks(col_indices, labels=col_indices)\n",
    "plt.yticks(row_indices, labels=row_indices)\n",
    "\n",
    "plt.title('RoPE (Rotary Positional Encoding)')\n",
    "plt.colorbar(label='Angulo de rotação normalizado')\n",
    "plt.xlabel('Posição do Embedding [x] (dimensão / 2) real+imaginary (complex numbers)')\n",
    "plt.ylabel('Posição relativa do token na sequencia')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMS Normalization (Model LayerNorm)\n",
    "\n",
    "Paper: https://arxiv.org/pdf/1910.07467.\n",
    "\n",
    "Ganho de performance vs Layer norm tradicional\n",
    "\n",
    "Exemplo: \n",
    "def layer_norm(embedding):\n",
    "    n = len(embedding)\n",
    "    mu = sum(embedding) / n  # Cálculo da média sem usar np.mean\n",
    "    sigma_squared = sum((a_i - mu) ** 2 for a_i in a) / n  # Cálculo da variância\n",
    "    sigma = np.sqrt(sigma_squared)  # Calculando o desvio padrão\n",
    "    g = np.ones_like(embedding)  # Parâmetro de ganho\n",
    "    embedding_normalized = (embedding - mu) / sigma * g  # Normalização\n",
    "    return embedding_normalized\n",
    "\n",
    "def rms_norm(embedding):\n",
    "    rms = np.sqrt(np.mean(embedding**2))  # Cálculo do RMS\n",
    "    g = np.ones_like(embedding)  # Parâmetro de ganho, inicializado como 1 para cada elemento\n",
    "    a_normalized = embedding / rms * g  # Normalização\n",
    "    return a_normalized\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2000, 0.4000, 0.6000, 0.2000, 0.4000, 0.6000],\n",
      "        [1.0000, 2.0000, 1.0000, 2.0000, 1.0000, 2.0000]])\n",
      "tensor([[0.4629, 0.9258, 1.3887, 0.4629, 0.9258, 1.3887],\n",
      "        [0.6325, 1.2649, 0.6325, 1.2649, 0.6325, 1.2649]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class RMSNorm(torch.nn.Module):\n",
    "    def __init__(self, dim: int, eps: float = 1e-6):\n",
    "        \"\"\"\n",
    "        Initialize the RMSNorm normalization layer.\n",
    "\n",
    "        Args:\n",
    "            dim (int): The dimension of the input tensor.\n",
    "            eps (float, optional): A small value added to the denominator for numerical stability. Default is 1e-6.\n",
    "\n",
    "        Attributes:\n",
    "            eps (float): A small value added to the denominator for numerical stability.\n",
    "            weight (nn.Parameter): Learnable scaling parameter.\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "\n",
    "    def _norm(self, x):\n",
    "        \"\"\"\n",
    "        Apply the RMSNorm normalization to the input tensor.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): The input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The normalized tensor.\n",
    "\n",
    "        \"\"\"\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the RMSNorm layer.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): The input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The output tensor after applying RMSNorm.\n",
    "\n",
    "        \"\"\"\n",
    "        output = self._norm(x.float()).type_as(x)\n",
    "        return output * self.weight\n",
    "\n",
    "\n",
    "#x = torch.randn(1, 2, 6)\n",
    "x = torch.tensor([[0.2,0.4,0.6,0.2,0.4,0.6],[1,2,1,2,1,2]])\n",
    "rmsnorm = RMSNorm(6)\n",
    "\n",
    "x_new = rmsnorm(x)\n",
    "\n",
    "print(x)\n",
    "print(x_new)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funcionamento dos operadores binarios do torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, True, False]\n",
      "[-2, -1, -2]\n",
      "[tensor(False), tensor(True), tensor(False)]\n",
      "tensor([False,  True, False])\n",
      "-----\n",
      ".... tensor([ True, False,  True])\n",
      ".... tensor([False, False,  True])\n",
      "-----\n",
      "[|=] tensor([ True, False,  True])\n",
      "[&=] tensor([False, False,  True])\n",
      "[^=] tensor([ True, False, False])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = [True, False, True]\n",
    "\n",
    "b = [not x for x in a]\n",
    "print(b)\n",
    "\n",
    "b = [~x for x in a]\n",
    "print(b)\n",
    "\n",
    "a = torch.tensor([True, False, True])\n",
    "\n",
    "b = [~x for x in a]\n",
    "print(b)\n",
    "\n",
    "b = ~a\n",
    "print(b)\n",
    "\n",
    "print(\"-----\")\n",
    "a = torch.tensor([True, False, True])\n",
    "b = torch.tensor([False, False, True])\n",
    "c = torch.tensor([False, False, True])\n",
    "d = torch.tensor([False, False, True])\n",
    "print(f\".... {a}\")\n",
    "print(f\".... {b}\")\n",
    "print(\"-----\")\n",
    "\n",
    "b |= a\n",
    "print(f\"[|=] {b}\")\n",
    "\n",
    "c &= a\n",
    "print(f\"[&=] {c}\")\n",
    "\n",
    "d ^= a\n",
    "print(f\"[^=] {d}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
