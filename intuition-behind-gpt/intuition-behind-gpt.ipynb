{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuição de como o GPT funciona internamente:\n",
    "\n",
    "A arquitetura do gpt tem como base o decoder da arquitetura transformer, lado direito da imagem abaixo:\n",
    "\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:1400/1*Jwataw7ZYsHU0XvDA-jVqQ.png\" alt=\"Transformer\" width=\"30%\" height=\"30%\">\n",
    "\n",
    "O fato do GPT usar o decoder somente, é devido ao foco do GPT prever o próximo token apenas cruzando o ultimo token com todos os anteriores exatamente como o decoder faz.\n",
    "\n",
    "Para quem não esta por dentro do termo token, imagine os tokens como uma palavrao que é digitada pelo usuário na pergunta e cada palavra que é gerada na resposta pelo GPT.\n",
    "\n",
    "Cada token tem um id unico em um vocabulario de palavras.\n",
    "\n",
    "Na pratica vc defini o que é um token, ele pode ser uma subword como no GPT, exemplo para formar a palavra casamento poderia ser a junção de dois tokens (casa + mento), ou poderiamos ter um vocabulario estremamente simples e enxuto com apenas as letras do alfabeto + numeros + caracteres especiais, neste caso para escrever casamento seriam 9 tokens (c,a,s,a,m,e,n,t,o)\n",
    "\n",
    "Referencias:\n",
    "- link para o paper: https://arxiv.org/pdf/1706.03762.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro passo é entender o conceito de similiaridade entre tokens e a representação do token o tal de \"embedding\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy\n",
    "%pip install torch\n",
    "%pip install scikit-learn\n",
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Checa se tem device NVIDIA ou MPS (mac gpu)\n",
    "if(torch.cuda.is_available()):\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# simplificar a visualização dos tensores\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "torch.set_default_device(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro vamos entender o que é Vocabulario, Token, Embedding:\n",
    "\n",
    "<img src=\"https://arize.com/wp-content/uploads/2022/06/blog-king-queen-embeddings.jpg\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criar nosso tokenizador\n",
    "\n",
    "vocabulario = {\n",
    "    0: \"chocolate\",\n",
    "    1: \"carne\",\n",
    "    2: \"arroz\",\n",
    "    3: \"caminhonete\",\n",
    "    4: \"pickup\",\n",
    "    5: \"carro\"\n",
    "}\n",
    "\n",
    "# nosso espaco vetorial que ira representar o significado das palavras foi definico com 4 dimensoes []\n",
    "# durante o treinamento nossa rede neural aprendeu:\n",
    "# o que cada dimensao representa no significado de todas as palavras do vocabulario\n",
    "embedding = {\n",
    "    0: \"comida\",\n",
    "    1: \"sabor\",\n",
    "    2: \"veiculo\",\n",
    "    3: \"carga\"\n",
    "}\n",
    "\n",
    "# para cada token no nosso vocabulario temos um vetor de embedding\n",
    "# o valores deste vetor foram aprendidos durante o treinamento da rede neural\n",
    "vocab_to_emb = {\n",
    "\n",
    "    # chocolate..:              comida, sabor, veiculo, carga\n",
    "    0          : torch.tensor([ 1.0   , 0.9  , 0.1    , 0.1  ]),\n",
    "\n",
    "    # carne......:              comida, sabor, veiculo, carga\n",
    "    1          : torch.tensor([ 1.0   , 0.8  , 0.01   , 0.01 ]),\n",
    "\n",
    "    # arroz......:              comida, sabor, veiculo, carga\n",
    "    2          : torch.tensor([ 1.0   , 0.7  , 0.01   , 0.01 ]),\n",
    "\n",
    "    # caminhonete:              comida, sabor, veiculo, carga\n",
    "    3          : torch.tensor([ 0.01  , 0.01 , 1.0    , 0.6 ]),\n",
    "\n",
    "    # pickup.....:              comida, sabor, veiculo, carga\n",
    "    4          : torch.tensor([ 0.01  , 0.01 , 1.0    , 0.5 ]),\n",
    "\n",
    "    # carro......:              comida, sabor, veiculo, carga\n",
    "    5          : torch.tensor([ 0.1   , 0.1  , 1.0    , 0.4 ])\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-118.410286  185.81895 ]\n",
      " [-108.26642   190.1955  ]\n",
      " [-101.61034   193.06862 ]\n",
      " [ 134.79817  -118.14217 ]\n",
      " [ 134.39478  -125.3808  ]\n",
      " [ 133.77992  -136.41135 ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plotar_tokens(vocabulario, vocab_to_emb, add=None, name=\"\"):\n",
    "    tensor_list = list(vocab_to_emb.values())\n",
    "    if(add is not None):\n",
    "        tensor_list.append(add)\n",
    "    \n",
    "    emb = torch.stack(tensor_list)\n",
    "\n",
    "    # criar uma instancia do TSNE\n",
    "    tsne = TSNE(n_components=2, perplexity=1)\n",
    "\n",
    "    # Aplicar o TSNE ao vetor original\n",
    "    emb_dimensao_reduzida = tsne.fit_transform(emb.cpu())\n",
    "    print(emb_dimensao_reduzida)\n",
    "\n",
    "    for token_id, token_emb in vocab_to_emb.items():\n",
    "        # plotar o vetor reduzido (x, y)\n",
    "        plt.scatter(emb_dimensao_reduzida[token_id][0], emb_dimensao_reduzida[token_id][1], label=vocabulario[token_id])\n",
    "    \n",
    "    if(add is not None):\n",
    "        plt.scatter(emb_dimensao_reduzida[-1][0], emb_dimensao_reduzida[-1][1], label=name)\n",
    "\n",
    "    # Definir rótulos dos eixos x e y\n",
    "    plt.xlabel('Eixo X')\n",
    "    plt.ylabel('Eixo Y')\n",
    "    plt.legend()\n",
    "\n",
    "    # Exibir o gráfico\n",
    "    plt.show()\n",
    "\n",
    "plotar_tokens(vocabulario, vocab_to_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como Calcular distancia ou similiaridade entre vetores:\n",
    "\n",
    "- Euclidian Distance<br>\n",
    "<img src=\"./img/euclidian.png\" alt=\"euclidian\" width=\"20%\" height=\"20%\">\n",
    "\n",
    "- Dot Product Similarity<br>\n",
    "<img src=\"./img/euclidian.png\" alt=\"euclidian\" width=\"20%\" height=\"20%\">\n",
    "\n",
    "- Consine Similarity<br>\n",
    "<img src=\"./img/euclidian.png\" alt=\"euclidian\" width=\"20%\" height=\"20%\">\n",
    "1.0 = \"0 grau\" | 0.0 = \"90 grau\" | -1 = \"180 grau\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distancia euclidiana: quanto menor mais proximo\n",
      "Distancia euclidiana entre chocolate e chocolate..:  tensor(0.)\n",
      "Distancia euclidiana entre chocolate e carne......:  tensor(0.1619)\n",
      "Distancia euclidiana entre chocolate e arroz......:  tensor(0.2371)\n",
      "Distancia euclidiana entre chocolate e caminhonete:  tensor(1.6829)\n",
      "Distancia euclidiana entre chocolate e pickup.....:  tensor(1.6560)\n",
      "Distancia euclidiana entre chocolate e carro......:  tensor(1.5330)\n",
      "\n",
      "Similiaridade dot_product: quanto maior mais similar\n",
      "Similiaridade dot_product entre chocolate e chocolate..:  tensor(1.8300)\n",
      "Similiaridade dot_product entre chocolate e carne......:  tensor(1.7220)\n",
      "Similiaridade dot_product entre chocolate e arroz......:  tensor(1.6320)\n",
      "Similiaridade dot_product entre chocolate e caminhonete:  tensor(0.1790)\n",
      "Similiaridade dot_product entre chocolate e pickup.....:  tensor(0.1690)\n",
      "Similiaridade dot_product entre chocolate e carro......:  tensor(0.3300)\n",
      "\n",
      "Similiaridade coseno: quanto maior mais similar\n",
      "Similiaridade coseno entre chocolate e chocolate..:  tensor(1.0000)\n",
      "Similiaridade coseno entre chocolate e carne......:  tensor(0.9939)\n",
      "Similiaridade coseno entre chocolate e arroz......:  tensor(0.9883)\n",
      "Similiaridade coseno entre chocolate e caminhonete:  tensor(0.1135)\n",
      "Similiaridade coseno entre chocolate e pickup.....:  tensor(0.1117)\n",
      "Similiaridade coseno entre chocolate e carro......:  tensor(0.2246)\n"
     ]
    }
   ],
   "source": [
    "def euclidian_distance(a, b):\n",
    "    return torch.sqrt(torch.sum((a - b) ** 2))\n",
    "\n",
    "def dot_product_similarity(a, b):\n",
    "    return torch.dot(a, b)\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return torch.dot(a, b) / (torch.norm(a) * torch.norm(b))\n",
    "\n",
    "print(\"Distancia euclidiana: quanto menor mais proximo\")\n",
    "print(\"Distancia euclidiana entre chocolate e chocolate..: \", euclidian_distance(vocab_to_emb[0], vocab_to_emb[0])) \n",
    "print(\"Distancia euclidiana entre chocolate e carne......: \", euclidian_distance(vocab_to_emb[0], vocab_to_emb[1])) \n",
    "print(\"Distancia euclidiana entre chocolate e arroz......: \", euclidian_distance(vocab_to_emb[0], vocab_to_emb[2]))\n",
    "print(\"Distancia euclidiana entre chocolate e caminhonete: \", euclidian_distance(vocab_to_emb[0], vocab_to_emb[3]))\n",
    "print(\"Distancia euclidiana entre chocolate e pickup.....: \", euclidian_distance(vocab_to_emb[0], vocab_to_emb[4]))\n",
    "print(\"Distancia euclidiana entre chocolate e carro......: \", euclidian_distance(vocab_to_emb[0], vocab_to_emb[5]))\n",
    "print()\n",
    "print(\"Similiaridade dot_product: quanto maior mais similar\")\n",
    "print(\"Similiaridade dot_product entre chocolate e chocolate..: \", dot_product_similarity(vocab_to_emb[0], vocab_to_emb[0])) \n",
    "print(\"Similiaridade dot_product entre chocolate e carne......: \", dot_product_similarity(vocab_to_emb[0], vocab_to_emb[1])) \n",
    "print(\"Similiaridade dot_product entre chocolate e arroz......: \", dot_product_similarity(vocab_to_emb[0], vocab_to_emb[2]))\n",
    "print(\"Similiaridade dot_product entre chocolate e caminhonete: \", dot_product_similarity(vocab_to_emb[0], vocab_to_emb[3]))\n",
    "print(\"Similiaridade dot_product entre chocolate e pickup.....: \", dot_product_similarity(vocab_to_emb[0], vocab_to_emb[4]))\n",
    "print(\"Similiaridade dot_product entre chocolate e carro......: \", dot_product_similarity(vocab_to_emb[0], vocab_to_emb[5]))\n",
    "print()\n",
    "print(\"Similiaridade coseno: quanto maior mais similar\")\n",
    "print(\"Similiaridade coseno entre chocolate e chocolate..: \", cosine_similarity(vocab_to_emb[0], vocab_to_emb[0])) \n",
    "print(\"Similiaridade coseno entre chocolate e carne......: \", cosine_similarity(vocab_to_emb[0], vocab_to_emb[1])) \n",
    "print(\"Similiaridade coseno entre chocolate e arroz......: \", cosine_similarity(vocab_to_emb[0], vocab_to_emb[2]))\n",
    "print(\"Similiaridade coseno entre chocolate e caminhonete: \", cosine_similarity(vocab_to_emb[0], vocab_to_emb[3]))\n",
    "print(\"Similiaridade coseno entre chocolate e pickup.....: \", cosine_similarity(vocab_to_emb[0], vocab_to_emb[4]))\n",
    "print(\"Similiaridade coseno entre chocolate e carro......: \", cosine_similarity(vocab_to_emb[0], vocab_to_emb[5]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos entender como a arquitetura do decoder do transforme funciona para prever o proximo token\n",
    "Primeiro passo é entender o mecanismo de self-attention:\n",
    " - Vou explicar de um modo siplificado, a idéia aqui é entender a intuição por traz do mecanismo de self-attention\n",
    "\n",
    "<img src=\"./img/self-attention.png\" alt=\"Self-Attention\" width=\"60%\" height=\"60%\">\n",
    "\n",
    "Neste exemplo iremos mostrar como o cruzamento de tokens acontece e como isto afeta a previsao da próxima palavra\n",
    "\n",
    "Bom vamos cruzar estes 2 tokens:\n",
    "carro + chocolate\n",
    "\n",
    "![imagem](https://st2.depositphotos.com/1362337/10378/i/380/depositphotos_103789698-stock-photo-little-chocolate-retro-pickup-truck.jpg)\n",
    "\n",
    "Neste exemplo não estamos adicionando os pesos treinaveis para simplicar o entendimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token sequence: 'carro chocolate'\n",
      "query[chocolate]:\n",
      "tensor([0.1000, 0.1000, 1.0000, 0.4000])\n",
      "Ultimo token da sequencia\n",
      "\n",
      "keys[carro, chocolate]:\n",
      "tensor([[1.0000, 0.9000, 0.1000, 0.1000],\n",
      "        [0.1000, 0.1000, 1.0000, 0.4000]])\n",
      "\n",
      "values[carro, chocolate]:\n",
      "tensor([[1.0000, 0.9000, 0.1000, 0.1000],\n",
      "        [0.1000, 0.1000, 1.0000, 0.4000]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tokens\n",
    "# token: id: 0, value: chocolate\n",
    "# token: id: 5, value: carro\n",
    "emb_chocolate = vocab_to_emb[0]\n",
    "emb_carro = vocab_to_emb[5]\n",
    "\n",
    "# sequencia = carro + chocolate\n",
    "# query =  [chocolate] (ultimo token)\n",
    "query = emb_carro\n",
    "\n",
    "# keys = [carro, chocolate]\n",
    "keys = torch.stack((emb_chocolate,emb_carro))\n",
    "\n",
    "# values = [carro, chocolate]\n",
    "values = torch.stack((emb_chocolate,emb_carro))\n",
    "\n",
    "print(f\"token sequence: 'carro chocolate'\")\n",
    "print(f\"query[chocolate]:\\n{query}\\nUltimo token da sequencia\\n\")\n",
    "print(f\"keys[carro, chocolate]:\\n{keys}\\n\")\n",
    "print(f\"values[carro, chocolate]:\\n{values}\\n\")\n",
    "\n",
    "plotar_tokens(vocabulario, vocab_to_emb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dot Product\n",
    "\n",
    "<img src=\"./img/dotproductvisual.png\" alt=\"dot product\" width=\"20%\" height=\"20%\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- query: chocolate -> key/value: chocolate ---------- \n",
      "query..: tensor([0.1000, 0.1000, 1.0000, 0.4000])\n",
      "keys...: tensor([0.1000, 0.1000, 1.0000, 0.4000])\n",
      "q*k....: tensor([0.0100, 0.0100, 1.0000, 0.1600])\n",
      "soma...: 1.1799999475479126\n",
      "\n",
      "---------- query: chocolate -> key/value: carro ---------- \n",
      "query..: tensor([0.1000, 0.1000, 1.0000, 0.4000])\n",
      "keys...: tensor([1.0000, 0.9000, 0.1000, 0.1000])\n",
      "q*k....: tensor([0.1000, 0.0900, 0.1000, 0.0400])\n",
      "soma...: 0.32999998331069946\n",
      "\n",
      "---------- softmax [chocolate_chocolate, chocolate_carro] ---------- \n",
      "scores.: tensor([0.7006, 0.2994])\n",
      "\n",
      "---------- vetores_de_saida_contextualizado (parciais: % de cada token) ---------- \n",
      "chocolate................: tensor([0.1000, 0.1000, 1.0000, 0.4000])\n",
      "multiplicado_por.........: 0.7005671858787537\n",
      "saida_chocolate_chocolate: tensor([0.0701, 0.0701, 0.7006, 0.2802])\n",
      "\n",
      "carro....................: tensor([1.0000, 0.9000, 0.1000, 0.1000])\n",
      "multiplicado_por.........: 0.2994329035282135\n",
      "saida_chocolate_carro....: tensor([0.2994, 0.2695, 0.0299, 0.0299])\n",
      "\n",
      "---------- vetor_de_saida_contextualizado (final: soma das parciais) ---------- \n",
      "saida_chocolate_chocolate (parcial): tensor([0.0701, 0.0701, 0.7006, 0.2802])\n",
      "saida_chocolate_carro.....(parcial): tensor([0.2994, 0.2695, 0.0299, 0.0299])\n",
      "Vetor contextualizado.....(final)..: tensor([0.3695, 0.3395, 0.7305, 0.3102])\n",
      "Embedding..........................:        [comida, sabor, veiculo, carga]\n"
     ]
    }
   ],
   "source": [
    "# Embeddings\n",
    "# keys[0] = emb_chocolate\n",
    "# keys[1] = emb_carro\n",
    "\n",
    "# values[0] = emb_chocolate\n",
    "# values[1] = emb_carro\n",
    "\n",
    "print(\"---------- query: chocolate -> key/value: chocolate ---------- \")\n",
    "print(f\"query..: {query}\\nkeys...: {keys[1]}\")\n",
    "\n",
    "score_chocolate_chocolate = query * keys[1] # query = chocolate & keys[1] = chocolate\n",
    "print(f\"q*k....: {score_chocolate_chocolate}\")\n",
    "\n",
    "score_chocolate_chocolate = torch.sum(score_chocolate_chocolate)\n",
    "print(f\"soma...: {score_chocolate_chocolate}\")\n",
    "\n",
    "print(\"\\n---------- query: chocolate -> key/value: carro ---------- \")\n",
    "print(f\"query..: {query}\\nkeys...: {keys[0]}\")\n",
    "\n",
    "score_chocolate_carro = query * keys[0] # query = chocolate & keys[0] = carro\n",
    "print(f\"q*k....: {score_chocolate_carro}\")\n",
    "\n",
    "score_chocolate_carro = torch.sum(score_chocolate_carro)\n",
    "print(f\"soma...: {score_chocolate_carro}\")\n",
    "\n",
    "print(\"\\n---------- softmax [chocolate_chocolate, chocolate_carro] ---------- \")\n",
    "scores = F.softmax(torch.stack((score_chocolate_chocolate, score_chocolate_carro)), dim=0)\n",
    "print(f\"scores.: {scores}\")\n",
    "\n",
    "print(\"\\n---------- vetores_de_saida_contextualizado (parciais: % de cada token) ---------- \")\n",
    "\n",
    "saida_chocolate_chocolate = scores[0] * values[1] # scores[0] = chocolate_chocolate * value[1] = chocolate\n",
    "print(f\"chocolate................: {values[1]}\")\n",
    "print(f\"multiplicado_por.........: {scores[0]}\")\n",
    "print(f\"saida_chocolate_chocolate: {saida_chocolate_chocolate}\")\n",
    "\n",
    "print()\n",
    "\n",
    "saida_chocolate_carro = scores[1] * values[0] # scores[1] = chocolate_carro * value[0] = carro\n",
    "print(f\"carro....................: {values[0]}\")\n",
    "print(f\"multiplicado_por.........: {scores[1]}\")\n",
    "print(f\"saida_chocolate_carro....: {saida_chocolate_carro}\")\n",
    "\n",
    "print(\"\\n---------- vetor_de_saida_contextualizado (final: soma das parciais) ---------- \")\n",
    "print(f\"saida_chocolate_chocolate (parcial): {saida_chocolate_chocolate}\")\n",
    "print(f\"saida_chocolate_carro.....(parcial): {saida_chocolate_carro}\")\n",
    "vetor_contextualizado = saida_chocolate_chocolate + saida_chocolate_carro\n",
    "print(f\"Vetor contextualizado.....(final)..: {vetor_contextualizado}\")\n",
    "print(\"Embedding..........................:        [comida, sabor, veiculo, carga]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- Simulando a aplicação de pesos treinados ---------- \n",
      "Embedding.............................:        [comida, sabor, veiculo, carga]\n",
      "Vetor contextualizado.....(final).....: tensor([0.3695, 0.3395, 0.7305, 0.3102])\n",
      "Pesos para multiplica.................: tensor([2.0000, 2.2000, 0.6000, 0.0100])\n",
      "Saida modelo para 'carro + chocolate'.: tensor([0.7390, 0.7470, 0.4383, 0.0031])\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n---------- Simulando a aplicação de pesos treinados ---------- \")\n",
    "print(\"Embedding.............................:        [comida, sabor, veiculo, carga]\")\n",
    "print(f\"Vetor contextualizado.....(final).....: {vetor_contextualizado}\")\n",
    "pesos = torch.tensor([2.0, 2.2, 0.6, 0.01])\n",
    "print(f\"Pesos para multiplica.................: {pesos}\")\n",
    "\n",
    "saida_modelo = vetor_contextualizado * pesos\n",
    "print(f\"Saida modelo para 'carro + chocolate'.: {saida_modelo}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entendo como o Decoder do Transformer trata uma sequencia de tokens para prever o proximo\n",
    "\n",
    "Para a sequencia de tokens:\n",
    "carro chocolate\n",
    "\n",
    "Agora temos a representacao mais contextualizada para o ultimo token \"chocolate\".\n",
    "- onde a nova composicao é basicamente:\n",
    "    - 30% do token carro\n",
    "    - 70% do token chocolate\n",
    "\n",
    "No exemplo anterior, apenas calculamos a saida do vetor contextualizado do ultimo token \"chocolate\" na sequencia \"carro chocolate\"\n",
    "\n",
    "Vamos agora explorar um exemplo de uma sequencia de tokens com processamento completo\n",
    "Imagine nossa rede neural agora com o seguinte vocabulario:\n",
    "- [eu, dei, racao, pro, meu, gato, cachorro, peixe]\n",
    "\n",
    "E estamos passando pelo decoder uma sequencia de tokens como esta:\n",
    "- eu dei racao pro meu\n",
    "\n",
    "Teremos os seguintes vetores de saida (S):\n",
    "- S0 = eu                   -> query: eu    -> (eu    x eu   )\n",
    "- S1 = eu dei               -> query: dei   -> (dei   x dei  ), (dei   x eu   )\n",
    "- S2 = eu dei racao         -> query: racao -> (racao x racao), (racao x dei  ), (racao x eu   )\n",
    "- S3 = eu dei racao pro     -> query: pro   -> (pro   x pro  ), (pro   x racao), (pro   x dei  ), (pro x eu )\n",
    "- S4 = eu dei racao pro meu -> query: meu   -> (meu   x meu  ), (meu   x pro  ), (meu   x racao), (meu x dei), (meu x eu)\n",
    "\n",
    "A rede neural utiliza este contexto para prever o proximo token, sendo basicamente a cada passada na rede um vetor do vocabulario com a probabilidade do proximo token:\n",
    "- Exemplo para o primeiro token\n",
    "    - Vetores de saida (contexto) -> probabilidade do proximo token (previsao)\n",
    "    - S0 -> usado para prever T1\n",
    "        - [eu......: 0.01]\n",
    "        - [dei.....: 0.93]\n",
    "        - [racao...: 0.01]\n",
    "        - [pro.....: 0.01]\n",
    "        - [meu.....: 0.01]\n",
    "        - [gato....: 0.01]\n",
    "        - [cachorro: 0.01]\n",
    "        - [peixe...: 0.01]\n",
    "\n",
    "- S1 ... S3 -> [...] ... [...]\n",
    "\n",
    "- Exemplo para o ultimo token: \"eu dei racao pro meu ...\"\n",
    "    - S4 -> usado para prever T5\n",
    "    - [eu......: 0.01]\n",
    "    - [dei.....: 0.01]\n",
    "    - [racao...: 0.01]\n",
    "    - [pro.....: 0.01]\n",
    "    - [meu.....: 0.01]\n",
    "    - [gato....: 0.35]\n",
    "    - [cachorro: 0.40]\n",
    "    - [peixe...: 0.20]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prevendo o proximo token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'eu', 1: 'dei', 2: 'racao', 3: 'pro', 4: 'meu', 5: 'gato', 6: 'cachorro', 7: 'peixe'}\n",
      "\n",
      "Camada Linear que reduz de embedding_size para vocab_size\n",
      "Linear(in_features=15, out_features=8, bias=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Gerando a camada final que converte Sx em probabilidades de proximo token\n",
    "\n",
    "vocabulario = {0: \"eu\", 1: \"dei\", 2: \"racao\", 3: \"pro\", 4: \"meu\", 5: \"gato\", 6: \"cachorro\", 7: \"peixe\"}\n",
    "vocab_size = len(vocabulario) # len == 8 -> [eu, dei, racao, pro, meu, gato, cachorro, peixe]\n",
    "embedding_size = 15 # tamanho da dimensao que contem a representação do token\n",
    "num_tokens = 1\n",
    "\n",
    "print(vocabulario)\n",
    "print()\n",
    "\n",
    "# Saida da camada transformer: para S4 (token \"meu\" contextualizado com \"eu + dei + racao + pro + meu\")\n",
    "# sequencia de tokens: \"eu  dei racao pro meu\" [next token]\n",
    "# sequencia de tokens: \"[0] [1] [2]   [3] [4]\" [next token]\n",
    "\n",
    "saida_decoder = torch.rand(num_tokens, embedding_size) # exemplo de uma saida da camada transformer para S4\n",
    "\n",
    "# Definindo a camada linear para redução de dimensionalidade\n",
    "# de embedding size para vocab size\n",
    "camada_linear_final = nn.Linear(embedding_size, vocab_size)\n",
    "print(\"Camada Linear que reduz de embedding_size para vocab_size\")\n",
    "print(camada_linear_final)\n",
    "\n",
    "\n",
    "# Setando dados para treinamento:\n",
    "\n",
    "# Definindo a função de perda\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Definindo o otimizador\n",
    "optimizer = optim.Adam(camada_linear_final.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logits: gerado com base no tamanho do vocab size\n",
      "tensor([[-0.0424, -0.2821,  0.0872,  0.2097, -0.0489, -0.0543,  0.2985, -0.4141]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "\n",
      "Probabilidade\n",
      "tensor([[0.1206, 0.0949, 0.1373, 0.1552, 0.1199, 0.1192, 0.1696, 0.0832]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "\n",
      "-------------------------------------------\n",
      "eu dei racao pro meu [next token]\n",
      "Token previsto: 6 -> cachorro\n",
      "Token correto.: 6 -> cachorro\n"
     ]
    }
   ],
   "source": [
    "# Passando pelo modelo (camada final de output)\n",
    "# Gerando logits\n",
    "logits = camada_linear_final(saida_decoder)\n",
    "print(\"\\nLogits: gerado com base no tamanho do vocab size\")\n",
    "print(logits)\n",
    "\n",
    "# Aplicando a softmax para obter probabilidades\n",
    "probabilidade = nn.Softmax(dim=1)(logits)\n",
    "print(\"\\nProbabilidade\")\n",
    "print(probabilidade)\n",
    "print()\n",
    "\n",
    "# Obtendo os índices máximos (índices de vocabulário) para cada token\n",
    "token_indice_previsto = torch.argmax(probabilidade, dim=1).item()\n",
    "\n",
    "print(\"-------------------------------------------\")\n",
    "print(\"eu dei racao pro meu [next token]\")\n",
    "print(f\"Token previsto: {token_indice_previsto} -> {vocabulario[token_indice_previsto]}\")\n",
    "\n",
    "# definir targets\n",
    "target = torch.tensor([6])\n",
    "print(f\"Token correto.: {target.item()} -> {vocabulario[target.item()]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinando o Modelo de predicao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.893663763999939\n"
     ]
    }
   ],
   "source": [
    "# Cálculo da loss\n",
    "loss = criterion(logits, target)\n",
    "\n",
    "# Backpropagation\n",
    "optimizer.zero_grad() # Zera os gradientes acumulados\n",
    "loss.backward()      # Calcula os gradientes\n",
    "optimizer.step()     # Atualiza os pesos\n",
    "\n",
    "print(\"Loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Camada Linear manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrada do modelo:\n",
      "tensor([[[ 0.5161,  0.1998, -0.2533,  0.4222],\n",
      "         [ 0.8155,  0.7504, -0.5165,  0.5845]]])\n",
      "torch.Size([1, 2, 4])\n",
      "\n",
      "Pesos do modelo:\n",
      "tensor([[ 1.0184, -0.4169, -0.0308, -1.4795],\n",
      "        [-0.4946,  0.3732,  1.7536, -1.3083],\n",
      "        [-0.2934,  0.4649,  0.5762,  0.4427],\n",
      "        [-0.0079, -0.3447,  0.0216,  0.2976],\n",
      "        [ 1.4353,  0.2518,  0.7408,  1.4431],\n",
      "        [-0.2053,  1.0915,  0.4405, -0.2802],\n",
      "        [ 0.7029, -0.6675,  0.1254,  0.7900],\n",
      "        [-0.0095, -0.8578,  0.2134,  1.6378]])\n",
      "torch.Size([8, 4])\n",
      "\n",
      "Bias do modelo:\n",
      "tensor([-1.4582])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "seq_len = 2\n",
    "embedding_size = 4 # in_features\n",
    "out_features = embedding_size * 2 # out_features, escalando para 2x o tamanho do embedding\n",
    "\n",
    "x = torch.randn(batch_size,seq_len,embedding_size)\n",
    "pesos = torch.randn(out_features, embedding_size)\n",
    "bias = torch.randn(1)\n",
    "\n",
    "print(\"Entrada do modelo:\")\n",
    "print(x)\n",
    "print(x.size())\n",
    "print()\n",
    "print(\"Pesos do modelo:\")\n",
    "print(pesos)\n",
    "print(pesos.size())\n",
    "print()\n",
    "print(\"Bias do modelo:\")\n",
    "print(bias)\n",
    "print(bias.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "x:\n",
      "tensor([[[ 0.5161,  0.1998, -0.2533,  0.4222],\n",
      "         [ 0.8155,  0.7504, -0.5165,  0.5845]]])\n",
      "torch.Size([1, 2, 4])\n",
      "\n",
      "Transposta pesos:\n",
      "tensor([[ 1.0184, -0.4946, -0.2934, -0.0079,  1.4353, -0.2053,  0.7029, -0.0095],\n",
      "        [-0.4169,  0.3732,  0.4649, -0.3447,  0.2518,  1.0915, -0.6675, -0.8578],\n",
      "        [-0.0308,  1.7536,  0.5762,  0.0216,  0.7408,  0.4405,  0.1254,  0.2134],\n",
      "        [-1.4795, -1.3083,  0.4427,  0.2976,  1.4431, -0.2802,  0.7900,  1.6378]])\n",
      "torch.Size([4, 8])\n",
      "\n",
      "saida:\n",
      "tensor([[[-0.1745, -1.1772, -0.0176,  0.0473,  1.2127, -0.1178,  0.5312,\n",
      "           0.4611],\n",
      "         [-0.3312, -1.7936,  0.0707, -0.1023,  1.8203,  0.2603,  0.4694,\n",
      "           0.1956]]])\n",
      "torch.Size([1, 2, 8])\n"
     ]
    }
   ],
   "source": [
    "transposta_pesos = pesos.transpose(0,1)\n",
    "print()\n",
    "print(\"x:\")\n",
    "print(x)\n",
    "print(x.size())\n",
    "print()\n",
    "print(\"Transposta pesos:\")\n",
    "print(transposta_pesos)\n",
    "print(transposta_pesos.size())\n",
    "\n",
    "saida = x @ transposta_pesos\n",
    "\n",
    "print()\n",
    "print(\"saida:\")\n",
    "print(saida)\n",
    "print(saida.size())\n",
    "\n",
    "saida = saida + bias\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gerando um embedding de uma sentença\n",
    "\n",
    "No cenário onde temos um sentença\n",
    "\n",
    "\"eu sou bruno\"\n",
    "\n",
    "Token[0] T0: eu\n",
    "Token[1] T1: sou\n",
    "Token[2] T2: bruno\n",
    "\n",
    "Queremos salvar na vector db uma única sentença que representa o contexto semantico dos 3 tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1000, 0.9000, 0.2000, 0.4000],\n",
      "        [0.2000, 0.1000, 0.8000, 0.7000],\n",
      "        [0.3000, 0.3000, 0.7000, 0.5000]])\n",
      "tensor([0.3000, 0.9000, 0.8000, 0.7000])\n",
      "tensor([0.2000, 0.4333, 0.5667, 0.5333])\n"
     ]
    }
   ],
   "source": [
    "# Saida do decoder\n",
    "S1 = torch.tensor([0.1, 0.9, 0.2, 0.4])\n",
    "S2 = torch.tensor([0.2, 0.1, 0.8, 0.7])\n",
    "S3 = torch.tensor([0.3, 0.3, 0.7, 0.5])\n",
    "sentence = torch.stack((S1, S2, S3))\n",
    "print(sentence)\n",
    "\n",
    "# Max Pooling\n",
    "max_pooling, _  = torch.max(sentence, dim=0)\n",
    "print(max_pooling)\n",
    "\n",
    "# Mean Pooling\n",
    "mean_pooling = torch.mean(sentence, dim=0)\n",
    "print(mean_pooling)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
